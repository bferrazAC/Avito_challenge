{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e50b25909919b31cc41f5585c7b45e64909133bb"
   },
   "source": [
    "# Avito Demand Prediction Challenge\n",
    "-> O que é<br/>\n",
    "-> O que queremos fazer<br/>\n",
    "-> Como pensamos em fazer, utilizando quais arquivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing important modules\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "from pandas import read_csv # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import tree\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import os\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "03e4208cd85d4fdbb23ddd784fa86be46eafad58",
    "collapsed": true
   },
   "source": [
    "* Explorar, visualizar,\n",
    "* sklearn preprocess encode\n",
    "* treino arvore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f00cf288c95d4801f3b5400c637c20678cc6e5a"
   },
   "source": [
    "Lendo CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "609ea2e890de76ce6be9aa58b31aa6289a5a3549"
   },
   "outputs": [],
   "source": [
    "#reading the csv's\n",
    "train = read_csv('../input/train.csv')\n",
    "test = read_csv('../input/test.csv')\n",
    "\n",
    "print ('Data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c3f9000b38454e20416e7fd09c907060972db4fe"
   },
   "outputs": [],
   "source": [
    "print('Train Columns ',train.columns)\n",
    "print('Test Columns ',test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "4f06dbd4b723bdde5290077c624701e27c3fe8ad"
   },
   "outputs": [],
   "source": [
    "#dropping some columns\n",
    "train = train.drop(['image', 'image_top_1'], axis = 1)\n",
    "test = test.drop(['image', 'image_top_1'], axis = 1)\n",
    "\n",
    "Y_df = train['deal_probability']\n",
    "train_df = train.drop(['item_id','activation_date','user_type', 'title','description','deal_probability'], axis = 1)\n",
    "enc_df = train.append(test).drop(['item_id','activation_date','user_type', 'title','description','deal_probability'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "b5cb38de352063d64e40fca426a0497a39a24580",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('Train shape: ',train.shape)\n",
    "print ('Test shape: ',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1d7b5cc9bd3279351d52f4d934bec6fc4bb2d4c2"
   },
   "outputs": [],
   "source": [
    "train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f0618cae0c981233d91417f02ad9acb71e0705b4",
    "collapsed": true
   },
   "source": [
    "# O que será testado\n",
    "Uma visualização melhor dos dados pode mostrar quais colunas são realmente importantes para o target. Logo de cara, *user_type* ou *user_type* não apresentam, intuitivamente, influência sobre a probabilidade. A Descrição e o título, por sua vez, tratam-se de textos e configuram um cenário que há de ser tratado distintamente dos demais dados categóricos.\n",
    "\n",
    "Um bom teste seria realizar um treino base com as colunas base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7e5d70010b1052fa5c7f42a815cc947722e1b8f5"
   },
   "outputs": [],
   "source": [
    "#transforming columns\n",
    "enc = {}\n",
    "for col in train_df.columns:\n",
    "    enc[col] = LabelEncoder()\n",
    "#     print (col)\n",
    "#     training with all data to avoid \"y unknown values\" when encoding the test data\n",
    "    enc[col].fit(enc_df[col].values.astype(str))\n",
    "#     encoding the train data\n",
    "    train_df[col] = enc[col].transform(train_df[col].values.astype(str))\n",
    "y_enc = LabelEncoder()\n",
    "Y_df = y_enc.fit_transform(Y_df)\n",
    "\n",
    "print (\"Label Encoding done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "fcee00006e8a6445313224fd4199574b49a8c126",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "36f2624559b39c47b0bbf4bbcab655d1f9b5a1c8"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "desc_df = train['description'][:50000]\n",
    "print ('Starting vectorizing')\n",
    "hash_vect = HashingVectorizer(n_features = 2**10, encoding = 'KOI8-R', stop_words = stopwords.words('russian'))\n",
    "count_vect = CountVectorizer(encoding = 'KOI8-R', stop_words = stopwords.words('russian'))\n",
    "# tfidf_transf = TfidfTransformer()\n",
    "\n",
    "desc_vec = hash_vect.fit_transform(desc_df.values.astype(str))\n",
    "sparse_desc = pd.SparseSeries(desc_vec.toarray().ravel(), fill_value=0)\n",
    "print (\"Vectorizing done\")\n",
    "# print (desc_df.values.astype(str))\n",
    "# desc_vec = count_vect.fit_transform(desc_df.values.astype(str))\n",
    "\n",
    "# desc_vec = tfidf_transf.fit_transform(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1dbe8eb2c26c7da7e1cb3831791fe3bdb867b00b"
   },
   "source": [
    "# Iniciando o treinamento com o dataset\n",
    "Nesta parte, será iniciado o treinamento com o dataset que foi pré-processado acima. Nós estamos utilizando *colocar os métodos utilizados aqui e seus motivos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "e763564c8f37ae65e2e9d091e69d8e864d7d81ac"
   },
   "outputs": [],
   "source": [
    "train_df_fit = train_df[:train_size]\n",
    "# print (desc_vec.todense()[0].)\n",
    "train_df_fit['description'] = sparse_desc[:train_size]\n",
    "# train_df_fit['description'] = desc_vec[:train_size]\n",
    "\n",
    "Y_df_fit = Y_df[:train_size]\n",
    "\n",
    "print ('Train shape: ',train_df_fit.shape)\n",
    "print ('Test shape: ',test.shape)\n",
    "print ('Y_df: ', Y_df_fit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "fa9e111ba1d06e9b36c2419396a02a54850ecc43"
   },
   "outputs": [],
   "source": [
    "#fazendo o treinamento com fit\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "print (train_df_fit.columns)\n",
    "clf = clf.fit(train_df_fit, Y_df_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "4dcaf55769edb0ccbe2686c1355d57bbfd9089e7"
   },
   "outputs": [],
   "source": [
    "#testando o quanto o modelo consegue acertar com score\n",
    "train_df_test = train_df[10000:15000]\n",
    "train_df_test['description'] = sparse_desc[10000:15000]\n",
    "Y_df_test = Y_df[10000:15000]\n",
    "clf.score(train_df_test, Y_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "720837f3e50f32527413c36ecbc4c065b3ba5f31"
   },
   "outputs": [],
   "source": [
    "#tirando colunas que não foram utilizadas\n",
    "test_size = 1000\n",
    "# print('Test labels: ', test)\n",
    "desc_test = test['description'][:test_size]\n",
    "test_df = test.drop(['item_id','activation_date','user_type', 'title','description'], axis = 1)\n",
    "test_df = test_df[:test_size]\n",
    "print('New test: ', test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "b614567734daaf709d75c396aaf476444f33ccf2"
   },
   "outputs": [],
   "source": [
    "#fazendo encoder\n",
    "for col in test_df.columns:\n",
    "    print (col)\n",
    "    test_df[col] = enc[col].transform(test_df[col].values.astype(str))\n",
    "\n",
    "desc_test_vec = hash_vect.transform(desc_test.values.astype(str))\n",
    "test_df['description'] = pd.SparseArray(desc_test_vec.toarray().ravel(), fill_value = 0)[:test_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "6071f69f942385f993234998e36b2d500236505e"
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "res = clf.predict(test_df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "c01a70edc3e5f7b16e9d7cacc2fd49731a1fad66"
   },
   "outputs": [],
   "source": [
    "y_enc.inverse_transform(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0997783b6f47cc3d3792204d4bbc475ce452249f",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
